{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import ijson\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#options = Options()\n",
    "#options.binary_location = 'C:/Program Files (x86)/Google/Chrome/Application/chrome.exe'\n",
    "chromedriver='C:/Users/default.DESKTOP-FVT3076/Desktop/crawl/chromedriver.exe'\n",
    "#chromedriver = 'C:/Program Files (x86)/Google/Chrome/Application/chrome.exe'\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "# f = open(f\"./data/data.json\", encoding=\"UTF-8\")\n",
    "# objects = ijson.items(f, 'item')\n",
    "# df = pd.DataFrame(objects)\n",
    "\n",
    "df = pd.read_csv('outputs/2021-09-24_부분_55391행.csv', sep=',', encoding='utf-8')\n",
    "start = 7000\n",
    "end = start + 1000\n",
    "\n",
    "df = df[start:end]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21913234\n"
     ]
    }
   ],
   "source": [
    "# url 테스트\n",
    "keyword = \"소하동%20콩이밥\"\n",
    "x = \"\"\n",
    "try:\n",
    "    naver_map_search_url = f\"https://m.map.naver.com/search2/search.naver?query={keyword}&sm=hty&style=v5\"\n",
    "#     naver_map_search_url = f\"https://www.google.com/maps/search/{keyword}\"\n",
    "    driver.get(naver_map_search_url)\n",
    "#         time.sleep(0.5)\n",
    "    x= driver.find_element_by_css_selector(\"#ct > div.search_listview._content._ctList > ul > li:nth-child(1) > div.item_info > a.a_item.a_item_distance._linkSiteview\").get_attribute('data-cid')\n",
    "    \n",
    "    # 네이버 지도 시스템은 data-cid에 url 파라미터를 저장해두고 있었습니다.\n",
    "    # data-cid 번호를 뽑아두었다가 기본 url 템플릿에 넣어 최종적인 url을 완성하면 됩니다.\n",
    "\n",
    "    #만약 검색 결과가 없다면?\n",
    "except Exception as e1:\n",
    "    if \"li:nth-child(1)\" in str(e1):  # -> \"child(1)이 없던데요?\"\n",
    "        print(e1)\n",
    "        try:\n",
    "            x = driver.find_element_by_css_selector(\"#ct > div.search_listview._content._ctList > ul > li > div.item_info > a.a_item.a_item_distance._linkSiteview\").get_attribute('data-cid')\n",
    "#                 time.sleep(0.5)print(x)\n",
    "        except Exception as e2:\n",
    "                        if i < 10:\n",
    "                            print(e2)\n",
    "                        x = np.nan\n",
    "        #                 time.sleep(0.5)\n",
    "    else:\n",
    "        pass\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 본격적으로 가게 상세페이지의 URL을 가져옵시다\n",
    "for i, keyword in enumerate(tqdm(df['naver_keyword'].tolist())):\n",
    "    if i < 10:\n",
    "        print(\"이번에 찾을 키워드 :\", i, f\"/ {df.shape[0] -1} 행\", keyword)\n",
    "# for i in crawl_range:\n",
    "#     keyword = df['naver_keyword'][i]\n",
    "#     print(\"이번에 찾을 키워드 :\", i, f\"/ {df.shape[0] -1} 행\", keyword)\n",
    "\n",
    "#     if(len(df['naver_map_url'].iloc[0]) > 37):\n",
    "#         print(df['naver_map_url'].iloc[0] + \" PASS\")\n",
    "#         continue\n",
    "    \n",
    "    try:\n",
    "        naver_map_search_url = f\"https://m.map.naver.com/search2/search.naver?query={keyword}&sm=hty&style=v5\"\n",
    "        driver.get(naver_map_search_url)\n",
    "        time.sleep(1)\n",
    "        df.iloc[i,-1] = driver.find_element_by_css_selector(\"#ct > div.search_listview._content._ctList > ul > li:nth-child(1) > div.item_info > a.a_item.a_item_distance._linkSiteview\").get_attribute('data-cid')\n",
    "        print(df.iloc[i,-1])\n",
    "        # 네이버 지도 시스템은 data-cid에 url 파라미터를 저장해두고 있었습니다.\n",
    "        # data-cid 번호를 뽑아두었다가 기본 url 템플릿에 넣어 최종적인 url을 완성하면 됩니다.\n",
    "        \n",
    "        #만약 검색 결과가 없다면?\n",
    "    except Exception as e1:\n",
    "        if \"li:nth-child(1)\" in str(e1):  # -> \"child(1)이 없던데요?\"\n",
    "            try:\n",
    "                df.iloc[i,-1] = driver.find_element_by_css_selector(\"#ct > div.search_listview._content._ctList > ul > li > div.item_info > a.a_item.a_item_distance._linkSiteview\").get_attribute('data-cid')\n",
    "                time.sleep(1)\n",
    "            except Exception as e2:\n",
    "                if i < 10:\n",
    "                    print(e2)\n",
    "                df.iloc[i,-1] = np.nan\n",
    "                print(\"못 찾은 키워드 :\", i, f\"/ {df.shape[0] -1} 행\", keyword)\n",
    "                time.sleep(1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "driver.quit() \n",
    "\n",
    "\n",
    "# 이때 수집한 것은 완전한 URL이 아니라 URL에 들어갈 ID (data-cid 라는 코드명으로 저장된) 이므로, 온전한 URL로 만들어줍니다\n",
    "\n",
    "df['naver_map_url'] = \"https://m.place.naver.com/restaurant/\" + df['naver_map_url']\n",
    "\n",
    "\n",
    "# URL이 수집되지 않은 데이터는 제거합니다.\n",
    "df = df.loc[~df['naver_map_url'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naver_map_type_list = []\n",
    "blog_review_list = []\n",
    "blog_review_qty_list = []\n",
    "naver_map_star_review_stars_list = []\n",
    "naver_map_star_review_qty_list = []\n",
    "\n",
    "# 메인 드라이버 : 별점 등을 크롤링\n",
    "driver = webdriver.Chrome(chromedriver) \n",
    "\n",
    "# 서브 드라이버 : 블로그 리뷰 텍스트를 리뷰 탭 들어가서 크롤링\n",
    "sub_driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "for i, url in enumerate(tqdm(df['naver_map_url'])):\n",
    "\n",
    "    driver.get(url)\n",
    "    sub_driver.get(url+\"/review/ugc\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        # 간단 정보 가져오기\n",
    "        # 네이버 지도의 유형 분류\n",
    "        naver_map_type = driver.find_element_by_css_selector(\"#_title > span._3ocDE\").text\n",
    "\n",
    "        # 블로그 리뷰 수\n",
    "        blog_review_qty = driver.find_element_by_css_selector(\"#app-root > div > div > div.place_detail_wrapper > div.place_section.no_margin.GCwOh > div > div > div._3XpyR > div > span:nth-child(3) > a > em\").text\n",
    "\n",
    "        # 블로그 별점 점수\n",
    "        star_review_stars = driver.find_element_by_css_selector(\"#app-root > div > div > div.place_detail_wrapper > div.place_section.no_margin.GCwOh > div > div > div._3XpyR > div > span._1Y6hi._1A8_M > em\").text\n",
    "\n",
    "        # 블로그 별점 평가 수\n",
    "        star_review_qty = driver.find_element_by_css_selector(\"#app-root > div > div > div.place_detail_wrapper > div.place_section.no_margin.GCwOh > div > div > div._3XpyR > div > span:nth-child(2) > a > em\").text\n",
    "       \n",
    "\n",
    "        # 블로그 리뷰 텍스트 가져오기\n",
    "        review_text_list = [] # 임시 선언\n",
    "\n",
    "        \n",
    "        # 네이버 지도 블로그 리뷰 탭은 동적 웹사이트의 순서가 주문하기, 메뉴보기 등의 존재 여부로 다르기 때문에 css selector가 아니라 element 찾기로 진행\n",
    "        review_text_crawl_list = sub_driver.find_elements_by_class_name(\"_2CbII\")\n",
    "        \n",
    "        # find element's' 메소드를 통해 가져온 내용은 리스트로 저장되고, 리스트 타입을 풀어서(for문 사용) 임시 데이터에 모아 두어야 한다\n",
    "        for review_crawl_data in review_text_crawl_list:\n",
    "            review_text_list.append(review_crawl_data.find_element_by_tag_name('div').text)\n",
    "        \n",
    "        # 그 리스트에 저장된 텍스트 (한 식당에 대한 여러 리뷰들)를 한 텍스트 덩어리로 모아(join)줍니다.\n",
    "        review_text = ','.join(review_text_list)\n",
    "\n",
    "\n",
    "        blog_review_list.append(review_text)\n",
    "\n",
    "        naver_map_type_list.append(naver_map_type)\n",
    "        blog_review_qty_list.append(blog_review_qty)\n",
    "        naver_map_star_review_stars_list.append(star_review_stars)\n",
    "        naver_map_star_review_qty_list.append(star_review_qty)\n",
    "\n",
    "    # 리뷰가 없는 업체는 크롤링에 오류가 뜨므로 표기해둡니다.\n",
    "    except Exception as e1:\n",
    "        print(e1)\n",
    "        print(f\"{i}행 문제가 발생\")\n",
    "        \n",
    "        # 리뷰가 없으므로 null을 임시로 넣어줍니다.\n",
    "        blog_review_list.append('null')  \n",
    "        naver_map_type_list.append('null')\n",
    "        blog_review_qty_list.append('null')\n",
    "        naver_map_star_review_stars_list.append('null')\n",
    "        naver_map_star_review_qty_list.append('null')\n",
    "\n",
    "driver.quit()\n",
    "sub_driver.quit()\n",
    "\n",
    "df['naver_store_type'] = naver_map_type_list  # 네이버 상세페이지에서 크롤링한 업체 유형\n",
    "df['naver_star_point'] = naver_map_star_review_stars_list  # 네이버 상세페이지에서 평가한 별점 평점\n",
    "df['naver_star_point_qty'] = naver_map_star_review_qty_list  # 네이버 상세페이지에서 별점 평가를 한 횟수\n",
    "df['naver_blog_review_txt'] = blog_review_list  # 네이버 상세페이지에 나온 블로그 리뷰 텍스트들\n",
    "df['naver_blog_review_qty'] = blog_review_qty_list  # 네이버 상세페이지에 나온 블로그 리뷰의 총 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd ./Elastic용 data\n",
    "# ElasticSearch용\n",
    "temp = df[['name','area', 'address','latitude','longitude']]\n",
    "today = str(datetime.date(datetime.today()))\n",
    "file = 'ES_' + str(start) + '~' + str(end) + '행_' + today + '.csv'\n",
    "\n",
    "if os.path.isfile(file):\n",
    "    os.remove(file)\n",
    "temp.to_csv(file, encoding='utf-8')\n",
    "# df.to_csv(today + '_test.csv', encoding='cp949')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../BERT용 data\n",
    "# Bert용\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "temp = df[['name', 'naver_star_point','naver_blog_review_txt']]\n",
    "today = str(datetime.date(datetime.today()))\n",
    "file = 'Bert_' + str(start) + '~' + str(end) + '행_' + today + '.csv'\n",
    "\n",
    "if os.path.isfile(file):\n",
    "    os.remove(file)\n",
    "temp.to_csv(file, encoding='utf-8')\n",
    "# df.to_csv(today + '_test.csv', encoding='cp949')\n",
    "print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
